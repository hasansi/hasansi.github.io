<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HasanAI</title>
    <link>https://www.hasanai.com/</link>
    <description>Recent content on HasanAI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    
	<atom:link href="https://www.hasanai.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Clustering</title>
      <link>https://www.hasanai.com/projects/clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/projects/clustering/</guid>
      <description>Clustering Project The meta data of each session that the hackers used to connect to the servers of a large technology firm. These are the features of the data:
 &amp;lsquo;Session_Connection_Time&amp;rsquo;: How long the session lasted in minutes &amp;lsquo;Bytes Transferred&amp;rsquo;: Number of MB transferred during session &amp;lsquo;Kali_Trace_Used&amp;rsquo;: Indicates if the hacker was using Kali Linux &amp;lsquo;Servers_Corrupted&amp;rsquo;: Number of server corrupted during the attack &amp;lsquo;Pages_Corrupted&amp;rsquo;: Number of pages illegally accessed &amp;lsquo;Location&amp;rsquo;: Location attack came from (Probably useless because the hackers used VPNs) &amp;lsquo;WPM_Typing_Speed&amp;rsquo;: Their estimated typing speed based on session logs.</description>
    </item>
    
    <item>
      <title>email: hasan@hasanai.com</title>
      <link>https://www.hasanai.com/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/contact/</guid>
      <description>hasan@hasanai.com</description>
    </item>
    
    <item>
      <title>Industries</title>
      <link>https://www.hasanai.com/industries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/industries/</guid>
      <description>I solve business problems in e-commerce, marketing and other industries that require use of NLP.</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://www.hasanai.com/projects/linear_regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/projects/linear_regression/</guid>
      <description>Linear Regression Business Problem: Predict how many crew members will be needed for future ships made by Hyundai Heavy Industries Hyundai Heavy Industries.
Here is what the data looks like so far:
Description: Measurements of ship size, capacity, crew, and age for 158 cruise ships. Variables/Columns Ship Name 1-20 Cruise Line 21-40 Age (as of 2013) 46-48 Tonnage (1000s of tons) 50-56 passengers (100s) 58-64 Length (100s of feet) 66-72 Cabins (100s) 74-80 Passenger Density 82-88 Crew (100s) 90-96 It is saved in a csv file for you called &amp;ldquo;cruise_ship_info.</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://www.hasanai.com/projects/logistic_regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/projects/logistic_regression/</guid>
      <description>Logistic Regression Binary Customer Churn A marketing agency has many customers that use their service to produce ads for the client/customer websites. They&amp;rsquo;ve noticed that they have quite a bit of churn in clients(i.e customer stopped buying products). They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager.</description>
    </item>
    
    <item>
      <title>NLP</title>
      <link>https://www.hasanai.com/projects/nlp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/projects/nlp/</guid>
      <description>Natural Language Processing In this project, I&amp;rsquo;ll build a spam filter using various NLP tools as well as the Naive Bayes classifier.
I&amp;rsquo;ll use a classic dataset for this - UCI Repository SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection
# %load /home/ubuntu/projects/initialize.py import findspark findspark.init(&amp;#39;/home/ubuntu/spark-2.1.1-bin-hadoop2.7&amp;#39;) import pyspark from pyspark.sql import SparkSession app_name=&amp;#39;app&amp;#39; spark=SparkSession.builder.appName(app_name).getOrCreate()data = spark.read.csv(&amp;#34;data/SMSSpamCollection&amp;#34;,inferSchema=True,sep=&amp;#39;\t&amp;#39;)#seperated by tabs, not commadata = data.withColumnRenamed(&amp;#39;_c0&amp;#39;,&amp;#39;class&amp;#39;).withColumnRenamed(&amp;#39;_c1&amp;#39;,&amp;#39;text&amp;#39;)#re-label the _c0 and _c1 columnsdata.show()+-----+--------------------+ |class| text| +-----+--------------------+ | ham|Go until jurong p.</description>
    </item>
    
    <item>
      <title>Syed Hasan</title>
      <link>https://www.hasanai.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.hasanai.com/about/</guid>
      <description>859-230-1713 hasan@hasanai.com https://www.linkedin.com/in/hasansi https://github.com/hasansi
TECHNICAL SKILLS  Python, C++, MySQL, NumPy,Scikit-learn,Pandas, NLTK, Keras, PySpark, MLlib, Matplotlib, Seaborn, Dimple.js, Javascript, HTML, CSS, Beautiful Soup, Flask, Git, GCP, AWS EC2.  EDUCATION 2017–2018:Udacity Nanodegree in Data Science
2007–2016:University of KentuckyPhD. (ABD)inPhysics
 Performed regression analysis on radioactive source data from silicon detectors using Python and Root, for detector calibrations at the Los Alamos National Lab. Set up, calibrated, modified instrumentation for and performed the UCNB (Ultra Cold Neutron B) experiment, that resulted in improved position sensitivity, noise to signal ratio, resolution, fast timing of the detector system.</description>
    </item>
    
  </channel>
</rss>